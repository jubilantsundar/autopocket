{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "header"
   },
   "source": [
    "# Boltz-2 SAR Iterator - Google Colab Edition\n",
    "\n",
    "**Optimized for A100 GPU Runtime**\n",
    "\n",
    "This notebook runs iterative Boltz-2 protein-ligand cofolding simulations to correlate predicted affinities with experimental SAR data.\n",
    "\n",
    "---\n",
    "\n",
    "## Setup Instructions\n",
    "\n",
    "1. **Set Runtime**: Runtime → Change runtime type → **A100 GPU**\n",
    "2. **Run Setup**: Execute cells 1-3 to install dependencies\n",
    "3. **Upload Data**: Upload your CSV file with SMILES and Activity columns\n",
    "4. **Configure**: Set your protein sequence and parameters\n",
    "5. **Run**: Execute the main iteration cell\n",
    "6. **Download Results**: Get all output files\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "check_gpu"
   },
   "source": [
    "## 1. Check GPU Availability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "check_gpu_code"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import subprocess\n",
    "\n",
    "# Check GPU\n",
    "print(\"CUDA Available:\", torch.cuda.is_available())\n",
    "if torch.cuda.is_available():\n",
    "    print(\"GPU Name:\", torch.cuda.get_device_name(0))\n",
    "    print(\"GPU Memory:\", torch.cuda.get_device_properties(0).total_memory / 1e9, \"GB\")\n",
    "    \n",
    "    # Check if it's A100\n",
    "    gpu_name = torch.cuda.get_device_name(0)\n",
    "    if \"A100\" in gpu_name:\n",
    "        print(\"\\n✓ A100 GPU detected! Optimal for Boltz-2.\")\n",
    "    else:\n",
    "        print(f\"\\n⚠ Warning: {gpu_name} detected. A100 recommended for best performance.\")\n",
    "else:\n",
    "    print(\"\\n❌ No GPU detected! Please enable GPU: Runtime → Change runtime type → A100 GPU\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "install_deps"
   },
   "source": [
    "## 2. Install Dependencies\n",
    "\n",
    "This will take ~5-10 minutes on first run. Subsequent runs will be faster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "install_deps_code"
   },
   "outputs": [],
   "source": [
    "%%capture install_output\n",
    "\n",
    "# Install Boltz-2 with CUDA support\n",
    "!pip install -q boltz[cuda] -U\n",
    "\n",
    "# Install other dependencies\n",
    "!pip install -q pandas numpy pyyaml gemmi matplotlib seaborn scipy\n",
    "\n",
    "print(\"✓ All dependencies installed successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "verify_boltz"
   },
   "outputs": [],
   "source": [
    "# Verify Boltz installation\n",
    "!boltz --version 2>/dev/null || echo \"Boltz-2 installed (version check not available)\"\n",
    "print(\"\\n✓ Boltz-2 is ready to use!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "upload_files"
   },
   "source": [
    "## 3. Upload Tool Files\n",
    "\n",
    "Upload the `boltz2_sar_iterator.py` script from your local machine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "upload_tool"
   },
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "import os\n",
    "\n",
    "print(\"Please upload 'boltz2_sar_iterator.py'...\")\n",
    "uploaded = files.upload()\n",
    "\n",
    "# Verify upload\n",
    "if 'boltz2_sar_iterator.py' in uploaded:\n",
    "    print(\"\\n✓ Tool uploaded successfully!\")\n",
    "    !chmod +x boltz2_sar_iterator.py\n",
    "else:\n",
    "    print(\"\\n❌ Please upload 'boltz2_sar_iterator.py'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "upload_data"
   },
   "source": [
    "## 4. Upload Your Data Files\n",
    "\n",
    "Upload:\n",
    "- **CSV file** with SMILES and Activity columns (required)\n",
    "- **MSA file** (.a3m format, optional)\n",
    "- **Template file** (.pdb or .cif, optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "upload_data_code"
   },
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "import pandas as pd\n",
    "\n",
    "print(\"Upload your SAR data CSV file...\")\n",
    "uploaded = files.upload()\n",
    "\n",
    "# Find CSV file\n",
    "csv_files = [f for f in uploaded.keys() if f.endswith('.csv')]\n",
    "if csv_files:\n",
    "    csv_file = csv_files[0]\n",
    "    print(f\"\\n✓ CSV file uploaded: {csv_file}\")\n",
    "    \n",
    "    # Preview data\n",
    "    df = pd.read_csv(csv_file)\n",
    "    print(f\"\\nData preview ({len(df)} compounds):\")\n",
    "    print(df.head())\n",
    "    \n",
    "    # Validate columns\n",
    "    if 'SMILES' in df.columns and 'Activity' in df.columns:\n",
    "        print(\"\\n✓ Required columns found (SMILES, Activity)\")\n",
    "    else:\n",
    "        print(\"\\n⚠ Warning: CSV should have 'SMILES' and 'Activity' columns\")\n",
    "        print(f\"Found columns: {list(df.columns)}\")\n",
    "else:\n",
    "    print(\"\\n❌ No CSV file found. Please upload a CSV file.\")\n",
    "    csv_file = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "upload_optional"
   },
   "outputs": [],
   "source": [
    "# Optional: Upload MSA and/or template files\n",
    "print(\"Optional: Upload MSA (.a3m) and/or template (.pdb or .cif) files\")\n",
    "print(\"Press Cancel to skip if not using these files.\\n\")\n",
    "\n",
    "try:\n",
    "    uploaded_optional = files.upload()\n",
    "    \n",
    "    # Find MSA file\n",
    "    msa_file = next((f for f in uploaded_optional.keys() if f.endswith('.a3m')), None)\n",
    "    if msa_file:\n",
    "        print(f\"✓ MSA file uploaded: {msa_file}\")\n",
    "    \n",
    "    # Find template file\n",
    "    template_file = next((f for f in uploaded_optional.keys() if f.endswith(('.pdb', '.cif'))), None)\n",
    "    if template_file:\n",
    "        print(f\"✓ Template file uploaded: {template_file}\")\n",
    "        \n",
    "except:\n",
    "    print(\"No optional files uploaded.\")\n",
    "    msa_file = None\n",
    "    template_file = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "config"
   },
   "source": [
    "## 5. Configure Parameters\n",
    "\n",
    "Set your protein sequence and other parameters here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "config_code"
   },
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# CONFIGURATION - EDIT THESE VALUES\n",
    "# ============================================================================\n",
    "\n",
    "# Required: Your protein sequence\n",
    "PROTEIN_SEQUENCE = \"STNPPPPETSNPNKPKRQTNQLQYLLRVVLKTLWKHQFAWPFQQPVDAVKLNLPDYYKIIKTPMDMGTIKKRLENNYYWNAQECIQDFNTMFTNCYIYNKPGDDIVLMAEALEKLFLQKINELPTEETEIMIVQAKGRGRGRK\"\n",
    "\n",
    "# Target R² for convergence (0.0 to 1.0)\n",
    "TARGET_R2 = 0.7\n",
    "\n",
    "# Maximum number of iterations\n",
    "MAX_ITERATIONS = 10\n",
    "\n",
    "# Chain IDs\n",
    "PROTEIN_CHAIN = \"A\"\n",
    "LIGAND_CHAIN = \"L\"\n",
    "\n",
    "# Optional: Pocket residues (list of tuples: [(chain, residue), ...])\n",
    "# Example: [(\"A\", 107), (\"A\", 98)]\n",
    "POCKET_RESIDUES = []\n",
    "\n",
    "# Optional: Contact residues (list of tuples: [((chain1, res1), (chain2, res2), max_dist), ...])\n",
    "# Example: [((\"A\", 20), (\"B\", 27), 5.0)]\n",
    "CONTACT_RESIDUES = []\n",
    "\n",
    "# MSA settings\n",
    "USE_MSA_SERVER = True  # Set to False if you uploaded an MSA file\n",
    "\n",
    "# Output directory\n",
    "OUTPUT_DIR = \"/content/boltz2_output\"\n",
    "\n",
    "# Logging level (DEBUG, INFO, WARNING, ERROR)\n",
    "LOG_LEVEL = \"INFO\"\n",
    "\n",
    "# ============================================================================\n",
    "\n",
    "print(\"Configuration:\")\n",
    "print(f\"  Protein sequence length: {len(PROTEIN_SEQUENCE)} aa\")\n",
    "print(f\"  Target R²: {TARGET_R2}\")\n",
    "print(f\"  Max iterations: {MAX_ITERATIONS}\")\n",
    "print(f\"  Protein chain: {PROTEIN_CHAIN}, Ligand chain: {LIGAND_CHAIN}\")\n",
    "print(f\"  Pocket residues: {len(POCKET_RESIDUES)}\")\n",
    "print(f\"  Contact residues: {len(CONTACT_RESIDUES)}\")\n",
    "print(f\"  Use MSA server: {USE_MSA_SERVER}\")\n",
    "print(f\"  Output: {OUTPUT_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "create_config"
   },
   "source": [
    "## 6. Create Configuration File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "create_config_code"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Build configuration\n",
    "config = {\n",
    "    \"protein_sequence\": PROTEIN_SEQUENCE,\n",
    "    \"csv_path\": csv_file,\n",
    "    \"output_dir\": OUTPUT_DIR,\n",
    "    \"target_r2\": TARGET_R2,\n",
    "    \"max_iterations\": MAX_ITERATIONS,\n",
    "    \"use_msa_server\": USE_MSA_SERVER,\n",
    "    \"protein_chain_id\": PROTEIN_CHAIN,\n",
    "    \"ligand_chain_id\": LIGAND_CHAIN,\n",
    "    \"pocket_residues\": POCKET_RESIDUES,\n",
    "    \"contact_residues\": CONTACT_RESIDUES,\n",
    "    \"log_level\": LOG_LEVEL\n",
    "}\n",
    "\n",
    "# Add optional files\n",
    "if 'msa_file' in globals() and msa_file:\n",
    "    config[\"msa_path\"] = msa_file\n",
    "    config[\"use_msa_server\"] = False\n",
    "\n",
    "if 'template_file' in globals() and template_file:\n",
    "    config[\"template_file\"] = template_file\n",
    "    config[\"template_force\"] = True\n",
    "    config[\"template_threshold\"] = 2\n",
    "\n",
    "# Save config\n",
    "config_file = \"colab_config.json\"\n",
    "with open(config_file, 'w') as f:\n",
    "    json.dump(config, f, indent=2)\n",
    "\n",
    "print(f\"✓ Configuration saved to {config_file}\")\n",
    "print(\"\\nConfiguration:\")\n",
    "print(json.dumps(config, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "run_iterator"
   },
   "source": [
    "## 7. Run Boltz-2 SAR Iterator\n",
    "\n",
    "This cell will run the iterative predictions. Depending on the number of compounds and iterations, this can take:\n",
    "- **~2-5 minutes per compound** on A100 GPU\n",
    "- **10 compounds, 5 iterations** = ~20-50 minutes total\n",
    "\n",
    "Progress will be shown in real-time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "run_iterator_code"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"Starting Boltz-2 SAR Iterator\")\n",
    "print(f\"Start time: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# Run the iterator\n",
    "!python boltz2_sar_iterator.py --config {config_file}\n",
    "\n",
    "elapsed_time = time.time() - start_time\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(f\"Completed in {elapsed_time/60:.1f} minutes\")\n",
    "print(f\"End time: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "view_results"
   },
   "source": [
    "## 8. View Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "view_summary"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "output_path = Path(OUTPUT_DIR)\n",
    "\n",
    "# Load summary\n",
    "summary_file = output_path / \"summary.json\"\n",
    "if summary_file.exists():\n",
    "    with open(summary_file, 'r') as f:\n",
    "        summary = json.load(f)\n",
    "    \n",
    "    print(\"=\"*80)\n",
    "    print(\"SUMMARY\")\n",
    "    print(\"=\"*80)\n",
    "    print(f\"Converged: {summary['converged']}\")\n",
    "    print(f\"Final R²: {summary['final_r2']:.4f}\")\n",
    "    print(f\"Target R²: {summary['target_r2']}\")\n",
    "    print(f\"Iterations run: {summary['iterations_run']}/{summary['max_iterations']}\")\n",
    "    print(f\"Successful predictions: {summary['successful_predictions']}/{summary['total_compounds']}\")\n",
    "    print(\"=\"*80)\n",
    "else:\n",
    "    print(\"Summary file not found. Check if the run completed successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "view_results_table"
   },
   "outputs": [],
   "source": [
    "# Display results table\n",
    "results_file = output_path / \"final_results.csv\"\n",
    "if results_file.exists():\n",
    "    df_results = pd.read_csv(results_file)\n",
    "    print(\"\\nFinal Results:\")\n",
    "    print(df_results.to_string(index=False))\n",
    "    \n",
    "    # Statistics\n",
    "    df_valid = df_results.dropna(subset=['Predicted_Affinity'])\n",
    "    if len(df_valid) > 0:\n",
    "        print(\"\\nStatistics:\")\n",
    "        print(f\"Mean experimental activity: {df_valid['Experimental_Activity'].mean():.2f}\")\n",
    "        print(f\"Mean predicted affinity: {df_valid['Predicted_Affinity'].mean():.2f}\")\n",
    "        corr = df_valid['Experimental_Activity'].corr(df_valid['Predicted_Affinity'])\n",
    "        print(f\"Pearson correlation: {corr:.3f}\")\n",
    "else:\n",
    "    print(\"Results file not found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "view_iterations"
   },
   "outputs": [],
   "source": [
    "# Display iteration history\n",
    "iterations_file = output_path / \"iteration_history.csv\"\n",
    "if iterations_file.exists():\n",
    "    df_iter = pd.read_csv(iterations_file)\n",
    "    print(\"\\nIteration History:\")\n",
    "    print(df_iter.to_string(index=False))\n",
    "else:\n",
    "    print(\"Iteration history file not found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "visualize"
   },
   "source": [
    "## 9. Visualize Results\n",
    "\n",
    "Create plots showing correlation, convergence, and residuals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "upload_viz"
   },
   "outputs": [],
   "source": [
    "# Upload visualize_results.py if not already uploaded\n",
    "if not Path('visualize_results.py').exists():\n",
    "    print(\"Please upload 'visualize_results.py'...\")\n",
    "    uploaded_viz = files.upload()\n",
    "    if 'visualize_results.py' in uploaded_viz:\n",
    "        print(\"✓ Visualization script uploaded!\")\n",
    "        !chmod +x visualize_results.py\n",
    "else:\n",
    "    print(\"✓ Visualization script already available\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "create_plots"
   },
   "outputs": [],
   "source": [
    "# Generate plots\n",
    "if Path('visualize_results.py').exists():\n",
    "    !python visualize_results.py {OUTPUT_DIR}\n",
    "    \n",
    "    # Display plots inline\n",
    "    from IPython.display import Image, display\n",
    "    import matplotlib.pyplot as plt\n",
    "    \n",
    "    plot_files = [\n",
    "        output_path / \"correlation_plot.png\",\n",
    "        output_path / \"iteration_history.png\",\n",
    "        output_path / \"residual_analysis.png\"\n",
    "    ]\n",
    "    \n",
    "    for plot_file in plot_files:\n",
    "        if plot_file.exists():\n",
    "            print(f\"\\n{plot_file.name}:\")\n",
    "            display(Image(filename=str(plot_file)))\n",
    "else:\n",
    "    print(\"Visualization script not available. Upload visualize_results.py to create plots.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "download"
   },
   "source": [
    "## 10. Download Results\n",
    "\n",
    "Download all output files as a ZIP archive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "download_code"
   },
   "outputs": [],
   "source": [
    "import shutil\n",
    "from pathlib import Path\n",
    "\n",
    "# Create ZIP archive\n",
    "output_path = Path(OUTPUT_DIR)\n",
    "if output_path.exists():\n",
    "    zip_file = \"/content/boltz2_results.zip\"\n",
    "    shutil.make_archive(zip_file.replace('.zip', ''), 'zip', output_path)\n",
    "    \n",
    "    print(f\"✓ Created archive: {zip_file}\")\n",
    "    print(f\"Archive size: {Path(zip_file).stat().st_size / 1e6:.1f} MB\")\n",
    "    \n",
    "    # Download\n",
    "    print(\"\\nDownloading results...\")\n",
    "    files.download(zip_file)\n",
    "    print(\"✓ Download complete!\")\n",
    "else:\n",
    "    print(\"Output directory not found. Run the iterator first.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "download_individual"
   },
   "outputs": [],
   "source": [
    "# Download individual files\n",
    "print(\"Download individual files:\\n\")\n",
    "\n",
    "individual_files = [\n",
    "    output_path / \"final_results.csv\",\n",
    "    output_path / \"iteration_history.csv\",\n",
    "    output_path / \"summary.json\",\n",
    "    output_path / \"correlation_plot.png\",\n",
    "    output_path / \"iteration_history.png\",\n",
    "    output_path / \"residual_analysis.png\"\n",
    "]\n",
    "\n",
    "for file_path in individual_files:\n",
    "    if file_path.exists():\n",
    "        print(f\"Downloading: {file_path.name}\")\n",
    "        files.download(str(file_path))\n",
    "    else:\n",
    "        print(f\"Not found: {file_path.name}\")\n",
    "\n",
    "print(\"\\n✓ All available files downloaded!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cleanup"
   },
   "source": [
    "## 11. Cleanup (Optional)\n",
    "\n",
    "Free up space by removing intermediate files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cleanup_code"
   },
   "outputs": [],
   "source": [
    "import shutil\n",
    "\n",
    "# Ask for confirmation\n",
    "response = input(\"Delete intermediate prediction files to free up space? (yes/no): \")\n",
    "\n",
    "if response.lower() == 'yes':\n",
    "    predictions_dir = output_path / \"predictions\"\n",
    "    if predictions_dir.exists():\n",
    "        size_before = sum(f.stat().st_size for f in predictions_dir.rglob('*') if f.is_file()) / 1e6\n",
    "        shutil.rmtree(predictions_dir)\n",
    "        print(f\"✓ Freed {size_before:.1f} MB\")\n",
    "    \n",
    "    yaml_dir = output_path / \"yaml_inputs\"\n",
    "    if yaml_dir.exists():\n",
    "        shutil.rmtree(yaml_dir)\n",
    "        print(\"✓ Removed YAML input files\")\n",
    "else:\n",
    "    print(\"Cleanup cancelled.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tips"
   },
   "source": [
    "---\n",
    "\n",
    "## Tips for Colab Usage\n",
    "\n",
    "### Performance\n",
    "- **A100 GPU**: ~30s-2min per compound\n",
    "- **T4 GPU**: ~2-5min per compound (fallback if A100 unavailable)\n",
    "- **Runtime limits**: Colab Pro gives longer runtime (24hrs vs 12hrs)\n",
    "\n",
    "### Memory Management\n",
    "- Large proteins (>1000 aa) may need more memory\n",
    "- Process compounds in batches if needed\n",
    "- Clean up intermediate files to free space\n",
    "\n",
    "### Best Practices\n",
    "- Save results frequently (download ZIP)\n",
    "- Use smaller iteration counts for testing (e.g., 3-5)\n",
    "- Monitor GPU usage: `!nvidia-smi`\n",
    "- Keep Colab tab active to prevent disconnection\n",
    "\n",
    "### Troubleshooting\n",
    "- **Out of memory**: Reduce batch size or use smaller protein\n",
    "- **Timeout**: Download intermediate results, reduce iterations\n",
    "- **Disconnected**: Results are saved to `/content/` - rerun download cell\n",
    "\n",
    "---\n",
    "\n",
    "## Support\n",
    "\n",
    "- Check logs: `!cat /content/boltz2_output/boltz2_sar_iterator.log`\n",
    "- GPU status: `!nvidia-smi`\n",
    "- Disk usage: `!df -h`\n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "A100",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
